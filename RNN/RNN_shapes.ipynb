{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW-akO7Pj7Lb",
        "outputId": "5b6745cf-4e63-47a9-a791-b317693dd5e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc8ce96aee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 163ms/step\n",
            "\n",
            "\n",
            "Prediction Y_hat:  [[ 0.03226585 -0.5292032 ]] \n",
            "\n",
            "\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 10, 3)]           0         \n",
            "                                                                 \n",
            " simple_rnn_4 (SimpleRNN)    (None, 5)                 45        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2)                 12        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 57\n",
            "Trainable params: 57\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Input, SimpleRNN, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "\n",
        "# Things you should automatically know and have memorized\n",
        "# N = number of samples\n",
        "# T = sequence length\n",
        "# D = number of input features\n",
        "# M = number of hidden units\n",
        "# K = number of output units\n",
        "\n",
        "\n",
        "# Make some data\n",
        "N = 1\n",
        "T = 10\n",
        "D = 3\n",
        "K = 2\n",
        "X = np.random.randn(N, T, D)\n",
        "\n",
        "# Make an RNN (totally random sample, the result are meaningful ma serve capire le dimensioni dei layer)\n",
        "M = 5 # number of hidden units\n",
        "i = Input(shape=(T, D))\n",
        "x = SimpleRNN(M)(i)\n",
        "x = Dense(K)(x)\n",
        "#NB no output activation function -> regression (se no softmax)\n",
        "\n",
        "model = Model(i, x)\n",
        "\n",
        "# Get the output\n",
        "Yhat = model.predict(X)\n",
        "print(\"\\n\\nPrediction Y_hat: \", Yhat, \"\\n\\n\")\n",
        "\n",
        "# See if we can replicate this output\n",
        "# Get the weights first\n",
        "model.summary()\n",
        "\n",
        "# Dice che non Ã¨ ben chiaro come siano memorizzati i dati nella RNN (?), in questo caso in 3 array\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# See what are the hidden layer -> i 3 array\n",
        "model.layers[1].get_weights()\n",
        "# E dopo ne vediamo le shapes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahO-H1tWkOd9",
        "outputId": "a2b21e75-209f-4f25-e26d-ca6ac9897765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 0.5437574 ,  0.5717804 , -0.2592594 , -0.1813659 , -0.42967603],\n",
              "        [-0.4329113 , -0.7363736 , -0.11026406,  0.03758347,  0.54653865],\n",
              "        [-0.39470944, -0.5682249 ,  0.03112137,  0.3828748 ,  0.78273445]],\n",
              "       dtype=float32),\n",
              " array([[ 0.41293657,  0.7683233 ,  0.34412372,  0.32986805,  0.10921767],\n",
              "        [ 0.12821284, -0.06725136, -0.6990866 ,  0.6139556 ,  0.3367122 ],\n",
              "        [-0.17545147, -0.38737962,  0.48847145,  0.7066643 , -0.2849122 ],\n",
              "        [-0.8632086 ,  0.474762  , -0.12184922,  0.11463995, -0.03850234],\n",
              "        [ 0.19269802,  0.1723211 , -0.37337008,  0.04157759, -0.8899657 ]],\n",
              "       dtype=float32),\n",
              " array([0., 0., 0., 0., 0.], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check their shapes\n",
        "# Should make sense\n",
        "# First output is input > hidden\n",
        "# Second output is hidden > hidden\n",
        "# Third output is bias term (vector of length M)\n",
        "a, b, c = model.layers[1].get_weights()\n",
        "print(a.shape, b.shape, c.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH1YSnB9kQhk",
        "outputId": "8f8b4969-5412-47e9-ab1a-4191737ce407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 5) (5, 5) (5,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Otteniamo quindi i valori manualmente e li usamo per costruire noi la RNN\n",
        "Wx, Wh, bh = model.layers[1].get_weights()\n",
        "Wo, bo = model.layers[2].get_weights()\n",
        "\n",
        "h_last = np.zeros(M) # initial hidden state\n",
        "x = X[0] # the one and only sample\n",
        "Yhats = [] # where we store the outputs\n",
        "\n",
        "for t in range(T):\n",
        "  h = np.tanh(x[t].dot(Wx) + h_last.dot(Wh) + bh)\n",
        "  y = h.dot(Wo) + bo # we only care about this value on the last iteration\n",
        "  Yhats.append(y)\n",
        "  \n",
        "  # important: assign h to h_last\n",
        "  h_last = h\n",
        "\n",
        "# print the final output\n",
        "print(\"Y_hat: \", Yhats[-1])\n",
        "print(\"Y_hat Deve essere uguale a quello stampato precedentemente ottenuto con model.predict\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQ_jOd8tkUlP",
        "outputId": "cc17ef19-c1ea-4e01-d5aa-ab68dadf5ed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y_hat:  [ 0.03226589 -0.52920322]\n",
            "Y_hat Deve essere uguale a quello stampato precedentemente ottenuto con model.predict\n"
          ]
        }
      ]
    }
  ]
}