{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Daeed2j23ma6",
        "outputId": "dc34a8ab-f42e-44f1-cc43-f663acdcde65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "data=load_breast_cancer()\n",
        "type(data) # -> sklearn.utils.Bunch is a dictionary basically"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5p221tuU33Yv",
        "outputId": "c375a846-4518-4060-a38e-b7797d315e0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sklearn.utils.Bunch"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.keys()\n",
        "#dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_h6ibOB4dY4",
        "outputId": "1776ae72-d929-4ea6-9c5d-7edf04958f6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.data.shape\n",
        "#has 569 samples and 30 feature (569 x 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZ2USlvu42Pq",
        "outputId": "12ad5eb5-0db4-404c-fdb0-4d6b218c4da0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #sono 569 \"pazienti\" i cui nei sono classificati secondo 30 diverse caratteristiche\n",
        " #data.feature_name ritorna tali caratteristiche\n",
        " \n",
        " #abbiamo anche i targhet, i risultati 1=maligno 0=beningo\n",
        "\n",
        " #data.target\n",
        " #data.target_name\n",
        " #data.targhet_shape (sono solo le risposte, 569)"
      ],
      "metadata": {
        "id": "nfGjzOZx4-6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#split the data into train and test sets\n",
        "x=0\n",
        "y=1\n",
        "train=[0,0]\n",
        "test=[0,0]\n",
        "train[x], test[x], train[y], test[y] = train_test_split(data.data, data.target, test_size=0.33)\n",
        "print(train[x].shape)\n",
        "print(test[x].shape)\n",
        "N, D = train[x].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p86sfU_g6Tp7",
        "outputId": "b89890c8-54af-4546-ca8d-1b025dac0358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(381, 30)\n",
            "(188, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Adesso riscaliamo tutti i valri perch√® altrimenti variano in range troppo grosso e non uniformi\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "train[x] = scaler.fit_transform(train[x])\n",
        "test[x] = scaler.transform(test[x])\n"
      ],
      "metadata": {
        "id": "JtkIN5kq7qpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build the model\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(1,input_shape=(D,), activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "#train \n",
        "\n",
        "r=model.fit(train[x], train[y], validation_data=(test[x],test[y]), epochs=500)\n",
        "\n",
        "#l'oggetto ritornato contiene informazioni sul training process\n",
        "\n",
        "print(\"Train score:\", model.evaluate(train[x],train[y]))\n",
        "print(\"Test score:\", model.evaluate(test[x],test[y]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRhVgamF8ole",
        "outputId": "921c8e30-0ea8-412a-fb9b-d6982f20e7da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "12/12 [==============================] - 1s 24ms/step - loss: 0.6956 - accuracy: 0.5722 - val_loss: 0.6570 - val_accuracy: 0.6596\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6268 - accuracy: 0.6325 - val_loss: 0.5856 - val_accuracy: 0.7394\n",
            "Epoch 3/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5695 - accuracy: 0.6982 - val_loss: 0.5254 - val_accuracy: 0.8085\n",
            "Epoch 4/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5222 - accuracy: 0.7480 - val_loss: 0.4761 - val_accuracy: 0.8351\n",
            "Epoch 5/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7953 - val_loss: 0.4375 - val_accuracy: 0.8670\n",
            "Epoch 6/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4459 - accuracy: 0.8320 - val_loss: 0.4060 - val_accuracy: 0.8883\n",
            "Epoch 7/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.8556 - val_loss: 0.3799 - val_accuracy: 0.8989\n",
            "Epoch 8/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3913 - accuracy: 0.8714 - val_loss: 0.3583 - val_accuracy: 0.9043\n",
            "Epoch 9/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3697 - accuracy: 0.8819 - val_loss: 0.3396 - val_accuracy: 0.9149\n",
            "Epoch 10/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3507 - accuracy: 0.8950 - val_loss: 0.3234 - val_accuracy: 0.9202\n",
            "Epoch 11/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3336 - accuracy: 0.9055 - val_loss: 0.3094 - val_accuracy: 0.9255\n",
            "Epoch 12/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3185 - accuracy: 0.9134 - val_loss: 0.2969 - val_accuracy: 0.9362\n",
            "Epoch 13/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3053 - accuracy: 0.9265 - val_loss: 0.2854 - val_accuracy: 0.9362\n",
            "Epoch 14/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2928 - accuracy: 0.9291 - val_loss: 0.2750 - val_accuracy: 0.9362\n",
            "Epoch 15/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2817 - accuracy: 0.9396 - val_loss: 0.2656 - val_accuracy: 0.9309\n",
            "Epoch 16/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2714 - accuracy: 0.9396 - val_loss: 0.2572 - val_accuracy: 0.9309\n",
            "Epoch 17/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2621 - accuracy: 0.9396 - val_loss: 0.2494 - val_accuracy: 0.9309\n",
            "Epoch 18/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2536 - accuracy: 0.9423 - val_loss: 0.2420 - val_accuracy: 0.9415\n",
            "Epoch 19/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2456 - accuracy: 0.9449 - val_loss: 0.2352 - val_accuracy: 0.9521\n",
            "Epoch 20/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2382 - accuracy: 0.9501 - val_loss: 0.2288 - val_accuracy: 0.9521\n",
            "Epoch 21/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2313 - accuracy: 0.9528 - val_loss: 0.2229 - val_accuracy: 0.9521\n",
            "Epoch 22/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2248 - accuracy: 0.9528 - val_loss: 0.2176 - val_accuracy: 0.9521\n",
            "Epoch 23/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2189 - accuracy: 0.9554 - val_loss: 0.2124 - val_accuracy: 0.9521\n",
            "Epoch 24/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2132 - accuracy: 0.9580 - val_loss: 0.2073 - val_accuracy: 0.9521\n",
            "Epoch 25/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2079 - accuracy: 0.9606 - val_loss: 0.2026 - val_accuracy: 0.9574\n",
            "Epoch 26/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2029 - accuracy: 0.9633 - val_loss: 0.1984 - val_accuracy: 0.9574\n",
            "Epoch 27/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1983 - accuracy: 0.9659 - val_loss: 0.1942 - val_accuracy: 0.9628\n",
            "Epoch 28/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1937 - accuracy: 0.9659 - val_loss: 0.1903 - val_accuracy: 0.9628\n",
            "Epoch 29/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1895 - accuracy: 0.9659 - val_loss: 0.1866 - val_accuracy: 0.9681\n",
            "Epoch 30/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1855 - accuracy: 0.9659 - val_loss: 0.1831 - val_accuracy: 0.9681\n",
            "Epoch 31/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1817 - accuracy: 0.9685 - val_loss: 0.1797 - val_accuracy: 0.9681\n",
            "Epoch 32/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1782 - accuracy: 0.9685 - val_loss: 0.1765 - val_accuracy: 0.9681\n",
            "Epoch 33/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1746 - accuracy: 0.9711 - val_loss: 0.1734 - val_accuracy: 0.9681\n",
            "Epoch 34/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1714 - accuracy: 0.9711 - val_loss: 0.1704 - val_accuracy: 0.9681\n",
            "Epoch 35/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1682 - accuracy: 0.9711 - val_loss: 0.1676 - val_accuracy: 0.9681\n",
            "Epoch 36/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1652 - accuracy: 0.9711 - val_loss: 0.1648 - val_accuracy: 0.9681\n",
            "Epoch 37/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1624 - accuracy: 0.9738 - val_loss: 0.1622 - val_accuracy: 0.9681\n",
            "Epoch 38/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1596 - accuracy: 0.9738 - val_loss: 0.1599 - val_accuracy: 0.9681\n",
            "Epoch 39/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1571 - accuracy: 0.9764 - val_loss: 0.1573 - val_accuracy: 0.9681\n",
            "Epoch 40/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1544 - accuracy: 0.9764 - val_loss: 0.1549 - val_accuracy: 0.9681\n",
            "Epoch 41/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1520 - accuracy: 0.9764 - val_loss: 0.1528 - val_accuracy: 0.9681\n",
            "Epoch 42/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1496 - accuracy: 0.9738 - val_loss: 0.1506 - val_accuracy: 0.9681\n",
            "Epoch 43/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1474 - accuracy: 0.9738 - val_loss: 0.1486 - val_accuracy: 0.9681\n",
            "Epoch 44/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1453 - accuracy: 0.9738 - val_loss: 0.1466 - val_accuracy: 0.9681\n",
            "Epoch 45/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1431 - accuracy: 0.9738 - val_loss: 0.1444 - val_accuracy: 0.9681\n",
            "Epoch 46/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1411 - accuracy: 0.9738 - val_loss: 0.1425 - val_accuracy: 0.9681\n",
            "Epoch 47/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1391 - accuracy: 0.9738 - val_loss: 0.1407 - val_accuracy: 0.9681\n",
            "Epoch 48/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1373 - accuracy: 0.9738 - val_loss: 0.1390 - val_accuracy: 0.9681\n",
            "Epoch 49/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1354 - accuracy: 0.9738 - val_loss: 0.1373 - val_accuracy: 0.9681\n",
            "Epoch 50/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1337 - accuracy: 0.9738 - val_loss: 0.1354 - val_accuracy: 0.9734\n",
            "Epoch 51/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1319 - accuracy: 0.9738 - val_loss: 0.1341 - val_accuracy: 0.9734\n",
            "Epoch 52/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1303 - accuracy: 0.9738 - val_loss: 0.1324 - val_accuracy: 0.9734\n",
            "Epoch 53/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1287 - accuracy: 0.9738 - val_loss: 0.1311 - val_accuracy: 0.9734\n",
            "Epoch 54/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1272 - accuracy: 0.9738 - val_loss: 0.1294 - val_accuracy: 0.9734\n",
            "Epoch 55/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1256 - accuracy: 0.9738 - val_loss: 0.1280 - val_accuracy: 0.9734\n",
            "Epoch 56/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1241 - accuracy: 0.9738 - val_loss: 0.1267 - val_accuracy: 0.9734\n",
            "Epoch 57/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1226 - accuracy: 0.9738 - val_loss: 0.1255 - val_accuracy: 0.9734\n",
            "Epoch 58/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1213 - accuracy: 0.9764 - val_loss: 0.1239 - val_accuracy: 0.9734\n",
            "Epoch 59/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1200 - accuracy: 0.9790 - val_loss: 0.1225 - val_accuracy: 0.9734\n",
            "Epoch 60/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1186 - accuracy: 0.9764 - val_loss: 0.1215 - val_accuracy: 0.9734\n",
            "Epoch 61/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1174 - accuracy: 0.9790 - val_loss: 0.1202 - val_accuracy: 0.9734\n",
            "Epoch 62/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1161 - accuracy: 0.9790 - val_loss: 0.1189 - val_accuracy: 0.9734\n",
            "Epoch 63/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1149 - accuracy: 0.9790 - val_loss: 0.1180 - val_accuracy: 0.9734\n",
            "Epoch 64/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1137 - accuracy: 0.9790 - val_loss: 0.1168 - val_accuracy: 0.9734\n",
            "Epoch 65/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1126 - accuracy: 0.9790 - val_loss: 0.1160 - val_accuracy: 0.9734\n",
            "Epoch 66/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1114 - accuracy: 0.9790 - val_loss: 0.1148 - val_accuracy: 0.9734\n",
            "Epoch 67/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1103 - accuracy: 0.9790 - val_loss: 0.1138 - val_accuracy: 0.9734\n",
            "Epoch 68/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1093 - accuracy: 0.9816 - val_loss: 0.1127 - val_accuracy: 0.9734\n",
            "Epoch 69/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1082 - accuracy: 0.9816 - val_loss: 0.1117 - val_accuracy: 0.9734\n",
            "Epoch 70/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1072 - accuracy: 0.9816 - val_loss: 0.1107 - val_accuracy: 0.9734\n",
            "Epoch 71/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1062 - accuracy: 0.9816 - val_loss: 0.1099 - val_accuracy: 0.9734\n",
            "Epoch 72/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1053 - accuracy: 0.9816 - val_loss: 0.1090 - val_accuracy: 0.9734\n",
            "Epoch 73/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1043 - accuracy: 0.9816 - val_loss: 0.1081 - val_accuracy: 0.9734\n",
            "Epoch 74/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1034 - accuracy: 0.9816 - val_loss: 0.1075 - val_accuracy: 0.9734\n",
            "Epoch 75/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1025 - accuracy: 0.9843 - val_loss: 0.1066 - val_accuracy: 0.9734\n",
            "Epoch 76/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1016 - accuracy: 0.9843 - val_loss: 0.1059 - val_accuracy: 0.9734\n",
            "Epoch 77/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1008 - accuracy: 0.9843 - val_loss: 0.1051 - val_accuracy: 0.9734\n",
            "Epoch 78/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1000 - accuracy: 0.9869 - val_loss: 0.1043 - val_accuracy: 0.9734\n",
            "Epoch 79/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0991 - accuracy: 0.9869 - val_loss: 0.1036 - val_accuracy: 0.9734\n",
            "Epoch 80/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0983 - accuracy: 0.9869 - val_loss: 0.1030 - val_accuracy: 0.9734\n",
            "Epoch 81/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0975 - accuracy: 0.9869 - val_loss: 0.1023 - val_accuracy: 0.9734\n",
            "Epoch 82/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0968 - accuracy: 0.9869 - val_loss: 0.1015 - val_accuracy: 0.9734\n",
            "Epoch 83/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0960 - accuracy: 0.9869 - val_loss: 0.1009 - val_accuracy: 0.9734\n",
            "Epoch 84/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0952 - accuracy: 0.9869 - val_loss: 0.1004 - val_accuracy: 0.9734\n",
            "Epoch 85/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0946 - accuracy: 0.9869 - val_loss: 0.0997 - val_accuracy: 0.9734\n",
            "Epoch 86/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0938 - accuracy: 0.9869 - val_loss: 0.0991 - val_accuracy: 0.9734\n",
            "Epoch 87/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0932 - accuracy: 0.9869 - val_loss: 0.0986 - val_accuracy: 0.9734\n",
            "Epoch 88/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0925 - accuracy: 0.9869 - val_loss: 0.0980 - val_accuracy: 0.9734\n",
            "Epoch 89/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0918 - accuracy: 0.9869 - val_loss: 0.0976 - val_accuracy: 0.9734\n",
            "Epoch 90/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0912 - accuracy: 0.9869 - val_loss: 0.0971 - val_accuracy: 0.9734\n",
            "Epoch 91/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0905 - accuracy: 0.9843 - val_loss: 0.0966 - val_accuracy: 0.9734\n",
            "Epoch 92/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0899 - accuracy: 0.9843 - val_loss: 0.0961 - val_accuracy: 0.9734\n",
            "Epoch 93/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0893 - accuracy: 0.9843 - val_loss: 0.0955 - val_accuracy: 0.9734\n",
            "Epoch 94/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0887 - accuracy: 0.9843 - val_loss: 0.0951 - val_accuracy: 0.9734\n",
            "Epoch 95/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0881 - accuracy: 0.9843 - val_loss: 0.0947 - val_accuracy: 0.9734\n",
            "Epoch 96/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0875 - accuracy: 0.9843 - val_loss: 0.0942 - val_accuracy: 0.9787\n",
            "Epoch 97/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0869 - accuracy: 0.9843 - val_loss: 0.0939 - val_accuracy: 0.9787\n",
            "Epoch 98/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0864 - accuracy: 0.9843 - val_loss: 0.0935 - val_accuracy: 0.9787\n",
            "Epoch 99/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0858 - accuracy: 0.9843 - val_loss: 0.0932 - val_accuracy: 0.9787\n",
            "Epoch 100/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0853 - accuracy: 0.9843 - val_loss: 0.0928 - val_accuracy: 0.9787\n",
            "Epoch 101/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0848 - accuracy: 0.9843 - val_loss: 0.0924 - val_accuracy: 0.9787\n",
            "Epoch 102/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0843 - accuracy: 0.9869 - val_loss: 0.0920 - val_accuracy: 0.9787\n",
            "Epoch 103/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0838 - accuracy: 0.9869 - val_loss: 0.0916 - val_accuracy: 0.9787\n",
            "Epoch 104/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0832 - accuracy: 0.9869 - val_loss: 0.0914 - val_accuracy: 0.9787\n",
            "Epoch 105/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0828 - accuracy: 0.9869 - val_loss: 0.0910 - val_accuracy: 0.9787\n",
            "Epoch 106/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0823 - accuracy: 0.9869 - val_loss: 0.0907 - val_accuracy: 0.9787\n",
            "Epoch 107/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0818 - accuracy: 0.9869 - val_loss: 0.0904 - val_accuracy: 0.9787\n",
            "Epoch 108/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0814 - accuracy: 0.9869 - val_loss: 0.0902 - val_accuracy: 0.9787\n",
            "Epoch 109/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0809 - accuracy: 0.9869 - val_loss: 0.0899 - val_accuracy: 0.9787\n",
            "Epoch 110/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0804 - accuracy: 0.9869 - val_loss: 0.0896 - val_accuracy: 0.9787\n",
            "Epoch 111/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0800 - accuracy: 0.9869 - val_loss: 0.0894 - val_accuracy: 0.9787\n",
            "Epoch 112/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0796 - accuracy: 0.9869 - val_loss: 0.0891 - val_accuracy: 0.9787\n",
            "Epoch 113/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0791 - accuracy: 0.9869 - val_loss: 0.0889 - val_accuracy: 0.9787\n",
            "Epoch 114/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0787 - accuracy: 0.9869 - val_loss: 0.0886 - val_accuracy: 0.9787\n",
            "Epoch 115/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0783 - accuracy: 0.9869 - val_loss: 0.0884 - val_accuracy: 0.9787\n",
            "Epoch 116/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0779 - accuracy: 0.9869 - val_loss: 0.0883 - val_accuracy: 0.9787\n",
            "Epoch 117/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0775 - accuracy: 0.9869 - val_loss: 0.0880 - val_accuracy: 0.9787\n",
            "Epoch 118/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0771 - accuracy: 0.9869 - val_loss: 0.0878 - val_accuracy: 0.9787\n",
            "Epoch 119/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0767 - accuracy: 0.9869 - val_loss: 0.0877 - val_accuracy: 0.9787\n",
            "Epoch 120/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0763 - accuracy: 0.9869 - val_loss: 0.0875 - val_accuracy: 0.9787\n",
            "Epoch 121/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0760 - accuracy: 0.9869 - val_loss: 0.0872 - val_accuracy: 0.9787\n",
            "Epoch 122/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0756 - accuracy: 0.9869 - val_loss: 0.0870 - val_accuracy: 0.9787\n",
            "Epoch 123/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0752 - accuracy: 0.9869 - val_loss: 0.0869 - val_accuracy: 0.9787\n",
            "Epoch 124/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0748 - accuracy: 0.9869 - val_loss: 0.0867 - val_accuracy: 0.9787\n",
            "Epoch 125/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0745 - accuracy: 0.9869 - val_loss: 0.0865 - val_accuracy: 0.9787\n",
            "Epoch 126/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0742 - accuracy: 0.9869 - val_loss: 0.0864 - val_accuracy: 0.9787\n",
            "Epoch 127/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0738 - accuracy: 0.9869 - val_loss: 0.0862 - val_accuracy: 0.9787\n",
            "Epoch 128/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0735 - accuracy: 0.9869 - val_loss: 0.0861 - val_accuracy: 0.9787\n",
            "Epoch 129/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0731 - accuracy: 0.9869 - val_loss: 0.0860 - val_accuracy: 0.9787\n",
            "Epoch 130/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0728 - accuracy: 0.9869 - val_loss: 0.0858 - val_accuracy: 0.9787\n",
            "Epoch 131/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0725 - accuracy: 0.9869 - val_loss: 0.0856 - val_accuracy: 0.9787\n",
            "Epoch 132/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0721 - accuracy: 0.9869 - val_loss: 0.0855 - val_accuracy: 0.9787\n",
            "Epoch 133/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0718 - accuracy: 0.9869 - val_loss: 0.0854 - val_accuracy: 0.9787\n",
            "Epoch 134/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0715 - accuracy: 0.9869 - val_loss: 0.0853 - val_accuracy: 0.9787\n",
            "Epoch 135/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0712 - accuracy: 0.9869 - val_loss: 0.0852 - val_accuracy: 0.9787\n",
            "Epoch 136/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0709 - accuracy: 0.9869 - val_loss: 0.0851 - val_accuracy: 0.9787\n",
            "Epoch 137/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0706 - accuracy: 0.9869 - val_loss: 0.0850 - val_accuracy: 0.9787\n",
            "Epoch 138/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.9869 - val_loss: 0.0849 - val_accuracy: 0.9787\n",
            "Epoch 139/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0700 - accuracy: 0.9869 - val_loss: 0.0848 - val_accuracy: 0.9787\n",
            "Epoch 140/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.9869 - val_loss: 0.0847 - val_accuracy: 0.9787\n",
            "Epoch 141/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0694 - accuracy: 0.9869 - val_loss: 0.0846 - val_accuracy: 0.9787\n",
            "Epoch 142/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0691 - accuracy: 0.9869 - val_loss: 0.0846 - val_accuracy: 0.9787\n",
            "Epoch 143/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.9869 - val_loss: 0.0844 - val_accuracy: 0.9787\n",
            "Epoch 144/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.9869 - val_loss: 0.0844 - val_accuracy: 0.9787\n",
            "Epoch 145/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0683 - accuracy: 0.9869 - val_loss: 0.0843 - val_accuracy: 0.9787\n",
            "Epoch 146/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0680 - accuracy: 0.9869 - val_loss: 0.0842 - val_accuracy: 0.9787\n",
            "Epoch 147/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0678 - accuracy: 0.9869 - val_loss: 0.0841 - val_accuracy: 0.9787\n",
            "Epoch 148/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.9869 - val_loss: 0.0841 - val_accuracy: 0.9787\n",
            "Epoch 149/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0672 - accuracy: 0.9869 - val_loss: 0.0840 - val_accuracy: 0.9787\n",
            "Epoch 150/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0670 - accuracy: 0.9869 - val_loss: 0.0839 - val_accuracy: 0.9787\n",
            "Epoch 151/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.9869 - val_loss: 0.0839 - val_accuracy: 0.9787\n",
            "Epoch 152/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0665 - accuracy: 0.9869 - val_loss: 0.0838 - val_accuracy: 0.9787\n",
            "Epoch 153/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0662 - accuracy: 0.9869 - val_loss: 0.0837 - val_accuracy: 0.9787\n",
            "Epoch 154/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.9869 - val_loss: 0.0837 - val_accuracy: 0.9787\n",
            "Epoch 155/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.9869 - val_loss: 0.0837 - val_accuracy: 0.9787\n",
            "Epoch 156/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0655 - accuracy: 0.9869 - val_loss: 0.0836 - val_accuracy: 0.9787\n",
            "Epoch 157/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0653 - accuracy: 0.9869 - val_loss: 0.0835 - val_accuracy: 0.9787\n",
            "Epoch 158/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 0.9869 - val_loss: 0.0835 - val_accuracy: 0.9787\n",
            "Epoch 159/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.9869 - val_loss: 0.0835 - val_accuracy: 0.9787\n",
            "Epoch 160/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.9869 - val_loss: 0.0834 - val_accuracy: 0.9787\n",
            "Epoch 161/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0643 - accuracy: 0.9869 - val_loss: 0.0834 - val_accuracy: 0.9787\n",
            "Epoch 162/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0641 - accuracy: 0.9869 - val_loss: 0.0834 - val_accuracy: 0.9787\n",
            "Epoch 163/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0639 - accuracy: 0.9869 - val_loss: 0.0833 - val_accuracy: 0.9787\n",
            "Epoch 164/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0636 - accuracy: 0.9869 - val_loss: 0.0833 - val_accuracy: 0.9787\n",
            "Epoch 165/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0634 - accuracy: 0.9869 - val_loss: 0.0833 - val_accuracy: 0.9787\n",
            "Epoch 166/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 0.9869 - val_loss: 0.0832 - val_accuracy: 0.9787\n",
            "Epoch 167/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.9869 - val_loss: 0.0832 - val_accuracy: 0.9787\n",
            "Epoch 168/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0628 - accuracy: 0.9869 - val_loss: 0.0832 - val_accuracy: 0.9787\n",
            "Epoch 169/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0626 - accuracy: 0.9869 - val_loss: 0.0832 - val_accuracy: 0.9787\n",
            "Epoch 170/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.9869 - val_loss: 0.0831 - val_accuracy: 0.9787\n",
            "Epoch 171/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0622 - accuracy: 0.9869 - val_loss: 0.0831 - val_accuracy: 0.9787\n",
            "Epoch 172/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0619 - accuracy: 0.9869 - val_loss: 0.0831 - val_accuracy: 0.9787\n",
            "Epoch 173/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0618 - accuracy: 0.9869 - val_loss: 0.0831 - val_accuracy: 0.9787\n",
            "Epoch 174/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 0.9869 - val_loss: 0.0831 - val_accuracy: 0.9787\n",
            "Epoch 175/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0614 - accuracy: 0.9869 - val_loss: 0.0830 - val_accuracy: 0.9787\n",
            "Epoch 176/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0612 - accuracy: 0.9869 - val_loss: 0.0830 - val_accuracy: 0.9787\n",
            "Epoch 177/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0609 - accuracy: 0.9869 - val_loss: 0.0830 - val_accuracy: 0.9787\n",
            "Epoch 178/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0608 - accuracy: 0.9869 - val_loss: 0.0830 - val_accuracy: 0.9787\n",
            "Epoch 179/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0606 - accuracy: 0.9869 - val_loss: 0.0831 - val_accuracy: 0.9787\n",
            "Epoch 180/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0604 - accuracy: 0.9869 - val_loss: 0.0830 - val_accuracy: 0.9787\n",
            "Epoch 181/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0602 - accuracy: 0.9869 - val_loss: 0.0830 - val_accuracy: 0.9787\n",
            "Epoch 182/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0600 - accuracy: 0.9869 - val_loss: 0.0830 - val_accuracy: 0.9787\n",
            "Epoch 183/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0598 - accuracy: 0.9869 - val_loss: 0.0830 - val_accuracy: 0.9787\n",
            "Epoch 184/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0596 - accuracy: 0.9869 - val_loss: 0.0830 - val_accuracy: 0.9787\n",
            "Epoch 185/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0595 - accuracy: 0.9869 - val_loss: 0.0830 - val_accuracy: 0.9787\n",
            "Epoch 186/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0593 - accuracy: 0.9869 - val_loss: 0.0830 - val_accuracy: 0.9787\n",
            "Epoch 187/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0591 - accuracy: 0.9869 - val_loss: 0.0830 - val_accuracy: 0.9787\n",
            "Epoch 188/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0589 - accuracy: 0.9869 - val_loss: 0.0830 - val_accuracy: 0.9787\n",
            "Epoch 189/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0588 - accuracy: 0.9869 - val_loss: 0.0830 - val_accuracy: 0.9787\n",
            "Epoch 190/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0586 - accuracy: 0.9869 - val_loss: 0.0830 - val_accuracy: 0.9787\n",
            "Epoch 191/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0584 - accuracy: 0.9869 - val_loss: 0.0830 - val_accuracy: 0.9787\n",
            "Epoch 192/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0583 - accuracy: 0.9869 - val_loss: 0.0830 - val_accuracy: 0.9787\n",
            "Epoch 193/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0581 - accuracy: 0.9869 - val_loss: 0.0830 - val_accuracy: 0.9787\n",
            "Epoch 194/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0579 - accuracy: 0.9869 - val_loss: 0.0831 - val_accuracy: 0.9787\n",
            "Epoch 195/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0577 - accuracy: 0.9869 - val_loss: 0.0830 - val_accuracy: 0.9787\n",
            "Epoch 196/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0576 - accuracy: 0.9869 - val_loss: 0.0831 - val_accuracy: 0.9787\n",
            "Epoch 197/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0574 - accuracy: 0.9869 - val_loss: 0.0831 - val_accuracy: 0.9787\n",
            "Epoch 198/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0573 - accuracy: 0.9869 - val_loss: 0.0831 - val_accuracy: 0.9787\n",
            "Epoch 199/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0571 - accuracy: 0.9869 - val_loss: 0.0831 - val_accuracy: 0.9787\n",
            "Epoch 200/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0570 - accuracy: 0.9869 - val_loss: 0.0832 - val_accuracy: 0.9787\n",
            "Epoch 201/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0568 - accuracy: 0.9869 - val_loss: 0.0832 - val_accuracy: 0.9787\n",
            "Epoch 202/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0566 - accuracy: 0.9869 - val_loss: 0.0832 - val_accuracy: 0.9787\n",
            "Epoch 203/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0565 - accuracy: 0.9869 - val_loss: 0.0832 - val_accuracy: 0.9787\n",
            "Epoch 204/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0563 - accuracy: 0.9869 - val_loss: 0.0832 - val_accuracy: 0.9787\n",
            "Epoch 205/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0562 - accuracy: 0.9869 - val_loss: 0.0832 - val_accuracy: 0.9787\n",
            "Epoch 206/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0560 - accuracy: 0.9869 - val_loss: 0.0833 - val_accuracy: 0.9787\n",
            "Epoch 207/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0559 - accuracy: 0.9869 - val_loss: 0.0833 - val_accuracy: 0.9787\n",
            "Epoch 208/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0557 - accuracy: 0.9869 - val_loss: 0.0833 - val_accuracy: 0.9787\n",
            "Epoch 209/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0556 - accuracy: 0.9869 - val_loss: 0.0833 - val_accuracy: 0.9787\n",
            "Epoch 210/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0554 - accuracy: 0.9869 - val_loss: 0.0833 - val_accuracy: 0.9787\n",
            "Epoch 211/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0553 - accuracy: 0.9869 - val_loss: 0.0834 - val_accuracy: 0.9787\n",
            "Epoch 212/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0551 - accuracy: 0.9869 - val_loss: 0.0834 - val_accuracy: 0.9787\n",
            "Epoch 213/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0550 - accuracy: 0.9869 - val_loss: 0.0834 - val_accuracy: 0.9787\n",
            "Epoch 214/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0548 - accuracy: 0.9869 - val_loss: 0.0834 - val_accuracy: 0.9787\n",
            "Epoch 215/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0547 - accuracy: 0.9869 - val_loss: 0.0834 - val_accuracy: 0.9787\n",
            "Epoch 216/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0546 - accuracy: 0.9869 - val_loss: 0.0835 - val_accuracy: 0.9787\n",
            "Epoch 217/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0544 - accuracy: 0.9869 - val_loss: 0.0835 - val_accuracy: 0.9787\n",
            "Epoch 218/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0543 - accuracy: 0.9869 - val_loss: 0.0835 - val_accuracy: 0.9787\n",
            "Epoch 219/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0542 - accuracy: 0.9869 - val_loss: 0.0836 - val_accuracy: 0.9787\n",
            "Epoch 220/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0540 - accuracy: 0.9869 - val_loss: 0.0836 - val_accuracy: 0.9787\n",
            "Epoch 221/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0539 - accuracy: 0.9869 - val_loss: 0.0836 - val_accuracy: 0.9787\n",
            "Epoch 222/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0537 - accuracy: 0.9869 - val_loss: 0.0836 - val_accuracy: 0.9787\n",
            "Epoch 223/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0536 - accuracy: 0.9869 - val_loss: 0.0837 - val_accuracy: 0.9787\n",
            "Epoch 224/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0535 - accuracy: 0.9869 - val_loss: 0.0837 - val_accuracy: 0.9787\n",
            "Epoch 225/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0534 - accuracy: 0.9869 - val_loss: 0.0837 - val_accuracy: 0.9787\n",
            "Epoch 226/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0532 - accuracy: 0.9869 - val_loss: 0.0838 - val_accuracy: 0.9787\n",
            "Epoch 227/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0531 - accuracy: 0.9869 - val_loss: 0.0838 - val_accuracy: 0.9787\n",
            "Epoch 228/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0529 - accuracy: 0.9869 - val_loss: 0.0839 - val_accuracy: 0.9787\n",
            "Epoch 229/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0528 - accuracy: 0.9869 - val_loss: 0.0839 - val_accuracy: 0.9787\n",
            "Epoch 230/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0527 - accuracy: 0.9869 - val_loss: 0.0839 - val_accuracy: 0.9787\n",
            "Epoch 231/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0526 - accuracy: 0.9869 - val_loss: 0.0839 - val_accuracy: 0.9787\n",
            "Epoch 232/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0525 - accuracy: 0.9869 - val_loss: 0.0840 - val_accuracy: 0.9787\n",
            "Epoch 233/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0523 - accuracy: 0.9869 - val_loss: 0.0840 - val_accuracy: 0.9787\n",
            "Epoch 234/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0522 - accuracy: 0.9869 - val_loss: 0.0841 - val_accuracy: 0.9787\n",
            "Epoch 235/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0521 - accuracy: 0.9869 - val_loss: 0.0841 - val_accuracy: 0.9787\n",
            "Epoch 236/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0520 - accuracy: 0.9869 - val_loss: 0.0841 - val_accuracy: 0.9787\n",
            "Epoch 237/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0519 - accuracy: 0.9869 - val_loss: 0.0842 - val_accuracy: 0.9787\n",
            "Epoch 238/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0517 - accuracy: 0.9869 - val_loss: 0.0842 - val_accuracy: 0.9787\n",
            "Epoch 239/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0516 - accuracy: 0.9869 - val_loss: 0.0842 - val_accuracy: 0.9787\n",
            "Epoch 240/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0515 - accuracy: 0.9895 - val_loss: 0.0843 - val_accuracy: 0.9787\n",
            "Epoch 241/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0514 - accuracy: 0.9895 - val_loss: 0.0844 - val_accuracy: 0.9787\n",
            "Epoch 242/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0512 - accuracy: 0.9895 - val_loss: 0.0844 - val_accuracy: 0.9787\n",
            "Epoch 243/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0511 - accuracy: 0.9895 - val_loss: 0.0844 - val_accuracy: 0.9787\n",
            "Epoch 244/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0510 - accuracy: 0.9895 - val_loss: 0.0845 - val_accuracy: 0.9787\n",
            "Epoch 245/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0509 - accuracy: 0.9895 - val_loss: 0.0845 - val_accuracy: 0.9787\n",
            "Epoch 246/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0508 - accuracy: 0.9895 - val_loss: 0.0845 - val_accuracy: 0.9787\n",
            "Epoch 247/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0507 - accuracy: 0.9895 - val_loss: 0.0846 - val_accuracy: 0.9787\n",
            "Epoch 248/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0506 - accuracy: 0.9895 - val_loss: 0.0847 - val_accuracy: 0.9787\n",
            "Epoch 249/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0505 - accuracy: 0.9895 - val_loss: 0.0847 - val_accuracy: 0.9787\n",
            "Epoch 250/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0503 - accuracy: 0.9895 - val_loss: 0.0847 - val_accuracy: 0.9787\n",
            "Epoch 251/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0502 - accuracy: 0.9895 - val_loss: 0.0848 - val_accuracy: 0.9787\n",
            "Epoch 252/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0501 - accuracy: 0.9895 - val_loss: 0.0848 - val_accuracy: 0.9787\n",
            "Epoch 253/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0500 - accuracy: 0.9895 - val_loss: 0.0848 - val_accuracy: 0.9787\n",
            "Epoch 254/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0499 - accuracy: 0.9895 - val_loss: 0.0849 - val_accuracy: 0.9787\n",
            "Epoch 255/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0498 - accuracy: 0.9895 - val_loss: 0.0849 - val_accuracy: 0.9787\n",
            "Epoch 256/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0497 - accuracy: 0.9895 - val_loss: 0.0849 - val_accuracy: 0.9787\n",
            "Epoch 257/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0496 - accuracy: 0.9895 - val_loss: 0.0850 - val_accuracy: 0.9787\n",
            "Epoch 258/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0495 - accuracy: 0.9895 - val_loss: 0.0850 - val_accuracy: 0.9787\n",
            "Epoch 259/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0494 - accuracy: 0.9895 - val_loss: 0.0850 - val_accuracy: 0.9787\n",
            "Epoch 260/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0493 - accuracy: 0.9895 - val_loss: 0.0852 - val_accuracy: 0.9787\n",
            "Epoch 261/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0491 - accuracy: 0.9895 - val_loss: 0.0852 - val_accuracy: 0.9787\n",
            "Epoch 262/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0491 - accuracy: 0.9895 - val_loss: 0.0852 - val_accuracy: 0.9787\n",
            "Epoch 263/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0490 - accuracy: 0.9895 - val_loss: 0.0853 - val_accuracy: 0.9787\n",
            "Epoch 264/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0488 - accuracy: 0.9895 - val_loss: 0.0853 - val_accuracy: 0.9787\n",
            "Epoch 265/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0487 - accuracy: 0.9895 - val_loss: 0.0854 - val_accuracy: 0.9787\n",
            "Epoch 266/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0486 - accuracy: 0.9895 - val_loss: 0.0854 - val_accuracy: 0.9787\n",
            "Epoch 267/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0485 - accuracy: 0.9895 - val_loss: 0.0855 - val_accuracy: 0.9787\n",
            "Epoch 268/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0484 - accuracy: 0.9895 - val_loss: 0.0855 - val_accuracy: 0.9787\n",
            "Epoch 269/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0483 - accuracy: 0.9895 - val_loss: 0.0856 - val_accuracy: 0.9787\n",
            "Epoch 270/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0482 - accuracy: 0.9895 - val_loss: 0.0856 - val_accuracy: 0.9787\n",
            "Epoch 271/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0481 - accuracy: 0.9895 - val_loss: 0.0856 - val_accuracy: 0.9787\n",
            "Epoch 272/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0480 - accuracy: 0.9895 - val_loss: 0.0857 - val_accuracy: 0.9787\n",
            "Epoch 273/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0479 - accuracy: 0.9895 - val_loss: 0.0857 - val_accuracy: 0.9787\n",
            "Epoch 274/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0478 - accuracy: 0.9895 - val_loss: 0.0858 - val_accuracy: 0.9787\n",
            "Epoch 275/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0478 - accuracy: 0.9895 - val_loss: 0.0859 - val_accuracy: 0.9787\n",
            "Epoch 276/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0477 - accuracy: 0.9895 - val_loss: 0.0859 - val_accuracy: 0.9787\n",
            "Epoch 277/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0476 - accuracy: 0.9895 - val_loss: 0.0859 - val_accuracy: 0.9787\n",
            "Epoch 278/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0475 - accuracy: 0.9895 - val_loss: 0.0860 - val_accuracy: 0.9787\n",
            "Epoch 279/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0474 - accuracy: 0.9895 - val_loss: 0.0861 - val_accuracy: 0.9787\n",
            "Epoch 280/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0473 - accuracy: 0.9895 - val_loss: 0.0862 - val_accuracy: 0.9787\n",
            "Epoch 281/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0472 - accuracy: 0.9895 - val_loss: 0.0862 - val_accuracy: 0.9787\n",
            "Epoch 282/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0471 - accuracy: 0.9895 - val_loss: 0.0862 - val_accuracy: 0.9787\n",
            "Epoch 283/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0470 - accuracy: 0.9895 - val_loss: 0.0863 - val_accuracy: 0.9787\n",
            "Epoch 284/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0469 - accuracy: 0.9895 - val_loss: 0.0863 - val_accuracy: 0.9787\n",
            "Epoch 285/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0468 - accuracy: 0.9895 - val_loss: 0.0863 - val_accuracy: 0.9787\n",
            "Epoch 286/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0467 - accuracy: 0.9895 - val_loss: 0.0864 - val_accuracy: 0.9787\n",
            "Epoch 287/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0466 - accuracy: 0.9895 - val_loss: 0.0865 - val_accuracy: 0.9787\n",
            "Epoch 288/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0466 - accuracy: 0.9895 - val_loss: 0.0866 - val_accuracy: 0.9787\n",
            "Epoch 289/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0465 - accuracy: 0.9895 - val_loss: 0.0866 - val_accuracy: 0.9787\n",
            "Epoch 290/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0464 - accuracy: 0.9895 - val_loss: 0.0867 - val_accuracy: 0.9787\n",
            "Epoch 291/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0463 - accuracy: 0.9895 - val_loss: 0.0867 - val_accuracy: 0.9787\n",
            "Epoch 292/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0462 - accuracy: 0.9895 - val_loss: 0.0868 - val_accuracy: 0.9787\n",
            "Epoch 293/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0461 - accuracy: 0.9895 - val_loss: 0.0868 - val_accuracy: 0.9787\n",
            "Epoch 294/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0460 - accuracy: 0.9895 - val_loss: 0.0869 - val_accuracy: 0.9787\n",
            "Epoch 295/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0460 - accuracy: 0.9895 - val_loss: 0.0870 - val_accuracy: 0.9787\n",
            "Epoch 296/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0459 - accuracy: 0.9895 - val_loss: 0.0870 - val_accuracy: 0.9787\n",
            "Epoch 297/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0458 - accuracy: 0.9895 - val_loss: 0.0870 - val_accuracy: 0.9787\n",
            "Epoch 298/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0457 - accuracy: 0.9895 - val_loss: 0.0871 - val_accuracy: 0.9787\n",
            "Epoch 299/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0456 - accuracy: 0.9895 - val_loss: 0.0872 - val_accuracy: 0.9787\n",
            "Epoch 300/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0455 - accuracy: 0.9895 - val_loss: 0.0872 - val_accuracy: 0.9787\n",
            "Epoch 301/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0455 - accuracy: 0.9895 - val_loss: 0.0872 - val_accuracy: 0.9787\n",
            "Epoch 302/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0454 - accuracy: 0.9895 - val_loss: 0.0873 - val_accuracy: 0.9787\n",
            "Epoch 303/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0453 - accuracy: 0.9895 - val_loss: 0.0874 - val_accuracy: 0.9787\n",
            "Epoch 304/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0452 - accuracy: 0.9895 - val_loss: 0.0874 - val_accuracy: 0.9787\n",
            "Epoch 305/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0451 - accuracy: 0.9895 - val_loss: 0.0875 - val_accuracy: 0.9787\n",
            "Epoch 306/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0450 - accuracy: 0.9895 - val_loss: 0.0875 - val_accuracy: 0.9787\n",
            "Epoch 307/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0450 - accuracy: 0.9895 - val_loss: 0.0876 - val_accuracy: 0.9787\n",
            "Epoch 308/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0449 - accuracy: 0.9895 - val_loss: 0.0876 - val_accuracy: 0.9787\n",
            "Epoch 309/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0448 - accuracy: 0.9895 - val_loss: 0.0877 - val_accuracy: 0.9787\n",
            "Epoch 310/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0447 - accuracy: 0.9895 - val_loss: 0.0878 - val_accuracy: 0.9787\n",
            "Epoch 311/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0446 - accuracy: 0.9895 - val_loss: 0.0879 - val_accuracy: 0.9787\n",
            "Epoch 312/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0446 - accuracy: 0.9895 - val_loss: 0.0879 - val_accuracy: 0.9787\n",
            "Epoch 313/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0445 - accuracy: 0.9895 - val_loss: 0.0879 - val_accuracy: 0.9787\n",
            "Epoch 314/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0444 - accuracy: 0.9895 - val_loss: 0.0880 - val_accuracy: 0.9787\n",
            "Epoch 315/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0443 - accuracy: 0.9895 - val_loss: 0.0881 - val_accuracy: 0.9787\n",
            "Epoch 316/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0442 - accuracy: 0.9895 - val_loss: 0.0881 - val_accuracy: 0.9787\n",
            "Epoch 317/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0442 - accuracy: 0.9895 - val_loss: 0.0882 - val_accuracy: 0.9787\n",
            "Epoch 318/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0441 - accuracy: 0.9895 - val_loss: 0.0882 - val_accuracy: 0.9787\n",
            "Epoch 319/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0440 - accuracy: 0.9895 - val_loss: 0.0883 - val_accuracy: 0.9787\n",
            "Epoch 320/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0440 - accuracy: 0.9895 - val_loss: 0.0883 - val_accuracy: 0.9787\n",
            "Epoch 321/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0439 - accuracy: 0.9895 - val_loss: 0.0884 - val_accuracy: 0.9787\n",
            "Epoch 322/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0438 - accuracy: 0.9895 - val_loss: 0.0884 - val_accuracy: 0.9787\n",
            "Epoch 323/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0437 - accuracy: 0.9895 - val_loss: 0.0886 - val_accuracy: 0.9787\n",
            "Epoch 324/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0437 - accuracy: 0.9895 - val_loss: 0.0886 - val_accuracy: 0.9787\n",
            "Epoch 325/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0436 - accuracy: 0.9895 - val_loss: 0.0886 - val_accuracy: 0.9787\n",
            "Epoch 326/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0436 - accuracy: 0.9895 - val_loss: 0.0888 - val_accuracy: 0.9787\n",
            "Epoch 327/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0434 - accuracy: 0.9895 - val_loss: 0.0888 - val_accuracy: 0.9787\n",
            "Epoch 328/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0433 - accuracy: 0.9895 - val_loss: 0.0888 - val_accuracy: 0.9787\n",
            "Epoch 329/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0433 - accuracy: 0.9895 - val_loss: 0.0889 - val_accuracy: 0.9787\n",
            "Epoch 330/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0432 - accuracy: 0.9895 - val_loss: 0.0889 - val_accuracy: 0.9787\n",
            "Epoch 331/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0431 - accuracy: 0.9895 - val_loss: 0.0890 - val_accuracy: 0.9787\n",
            "Epoch 332/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0431 - accuracy: 0.9895 - val_loss: 0.0891 - val_accuracy: 0.9787\n",
            "Epoch 333/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0430 - accuracy: 0.9895 - val_loss: 0.0891 - val_accuracy: 0.9787\n",
            "Epoch 334/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0429 - accuracy: 0.9895 - val_loss: 0.0891 - val_accuracy: 0.9787\n",
            "Epoch 335/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0428 - accuracy: 0.9895 - val_loss: 0.0892 - val_accuracy: 0.9787\n",
            "Epoch 336/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0428 - accuracy: 0.9895 - val_loss: 0.0893 - val_accuracy: 0.9787\n",
            "Epoch 337/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0427 - accuracy: 0.9895 - val_loss: 0.0894 - val_accuracy: 0.9787\n",
            "Epoch 338/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0427 - accuracy: 0.9895 - val_loss: 0.0895 - val_accuracy: 0.9787\n",
            "Epoch 339/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0426 - accuracy: 0.9895 - val_loss: 0.0895 - val_accuracy: 0.9787\n",
            "Epoch 340/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0425 - accuracy: 0.9895 - val_loss: 0.0896 - val_accuracy: 0.9787\n",
            "Epoch 341/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0425 - accuracy: 0.9895 - val_loss: 0.0896 - val_accuracy: 0.9787\n",
            "Epoch 342/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0424 - accuracy: 0.9895 - val_loss: 0.0897 - val_accuracy: 0.9787\n",
            "Epoch 343/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0423 - accuracy: 0.9895 - val_loss: 0.0897 - val_accuracy: 0.9787\n",
            "Epoch 344/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0422 - accuracy: 0.9895 - val_loss: 0.0898 - val_accuracy: 0.9787\n",
            "Epoch 345/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0422 - accuracy: 0.9895 - val_loss: 0.0899 - val_accuracy: 0.9787\n",
            "Epoch 346/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0421 - accuracy: 0.9895 - val_loss: 0.0899 - val_accuracy: 0.9787\n",
            "Epoch 347/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0421 - accuracy: 0.9895 - val_loss: 0.0900 - val_accuracy: 0.9787\n",
            "Epoch 348/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0420 - accuracy: 0.9895 - val_loss: 0.0901 - val_accuracy: 0.9787\n",
            "Epoch 349/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0419 - accuracy: 0.9895 - val_loss: 0.0901 - val_accuracy: 0.9787\n",
            "Epoch 350/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0418 - accuracy: 0.9895 - val_loss: 0.0902 - val_accuracy: 0.9787\n",
            "Epoch 351/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0418 - accuracy: 0.9895 - val_loss: 0.0902 - val_accuracy: 0.9787\n",
            "Epoch 352/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0417 - accuracy: 0.9895 - val_loss: 0.0903 - val_accuracy: 0.9787\n",
            "Epoch 353/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0417 - accuracy: 0.9895 - val_loss: 0.0903 - val_accuracy: 0.9787\n",
            "Epoch 354/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0416 - accuracy: 0.9895 - val_loss: 0.0904 - val_accuracy: 0.9787\n",
            "Epoch 355/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0415 - accuracy: 0.9895 - val_loss: 0.0904 - val_accuracy: 0.9787\n",
            "Epoch 356/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0414 - accuracy: 0.9895 - val_loss: 0.0905 - val_accuracy: 0.9787\n",
            "Epoch 357/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0414 - accuracy: 0.9895 - val_loss: 0.0906 - val_accuracy: 0.9787\n",
            "Epoch 358/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0413 - accuracy: 0.9895 - val_loss: 0.0907 - val_accuracy: 0.9787\n",
            "Epoch 359/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0413 - accuracy: 0.9895 - val_loss: 0.0907 - val_accuracy: 0.9787\n",
            "Epoch 360/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0412 - accuracy: 0.9895 - val_loss: 0.0907 - val_accuracy: 0.9787\n",
            "Epoch 361/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0412 - accuracy: 0.9895 - val_loss: 0.0908 - val_accuracy: 0.9787\n",
            "Epoch 362/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0411 - accuracy: 0.9895 - val_loss: 0.0909 - val_accuracy: 0.9787\n",
            "Epoch 363/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0410 - accuracy: 0.9895 - val_loss: 0.0909 - val_accuracy: 0.9787\n",
            "Epoch 364/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0410 - accuracy: 0.9895 - val_loss: 0.0911 - val_accuracy: 0.9787\n",
            "Epoch 365/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0409 - accuracy: 0.9895 - val_loss: 0.0911 - val_accuracy: 0.9787\n",
            "Epoch 366/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0408 - accuracy: 0.9895 - val_loss: 0.0911 - val_accuracy: 0.9787\n",
            "Epoch 367/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0408 - accuracy: 0.9895 - val_loss: 0.0913 - val_accuracy: 0.9787\n",
            "Epoch 368/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0407 - accuracy: 0.9895 - val_loss: 0.0913 - val_accuracy: 0.9787\n",
            "Epoch 369/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0407 - accuracy: 0.9895 - val_loss: 0.0913 - val_accuracy: 0.9787\n",
            "Epoch 370/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0406 - accuracy: 0.9895 - val_loss: 0.0914 - val_accuracy: 0.9787\n",
            "Epoch 371/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0405 - accuracy: 0.9895 - val_loss: 0.0914 - val_accuracy: 0.9787\n",
            "Epoch 372/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0405 - accuracy: 0.9895 - val_loss: 0.0916 - val_accuracy: 0.9787\n",
            "Epoch 373/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0404 - accuracy: 0.9895 - val_loss: 0.0916 - val_accuracy: 0.9787\n",
            "Epoch 374/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0404 - accuracy: 0.9895 - val_loss: 0.0916 - val_accuracy: 0.9787\n",
            "Epoch 375/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0403 - accuracy: 0.9895 - val_loss: 0.0918 - val_accuracy: 0.9787\n",
            "Epoch 376/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0402 - accuracy: 0.9895 - val_loss: 0.0918 - val_accuracy: 0.9787\n",
            "Epoch 377/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0402 - accuracy: 0.9895 - val_loss: 0.0919 - val_accuracy: 0.9787\n",
            "Epoch 378/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0401 - accuracy: 0.9895 - val_loss: 0.0919 - val_accuracy: 0.9787\n",
            "Epoch 379/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0401 - accuracy: 0.9895 - val_loss: 0.0920 - val_accuracy: 0.9787\n",
            "Epoch 380/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0400 - accuracy: 0.9895 - val_loss: 0.0921 - val_accuracy: 0.9787\n",
            "Epoch 381/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0400 - accuracy: 0.9895 - val_loss: 0.0922 - val_accuracy: 0.9787\n",
            "Epoch 382/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0399 - accuracy: 0.9895 - val_loss: 0.0922 - val_accuracy: 0.9787\n",
            "Epoch 383/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0398 - accuracy: 0.9895 - val_loss: 0.0922 - val_accuracy: 0.9787\n",
            "Epoch 384/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0398 - accuracy: 0.9895 - val_loss: 0.0923 - val_accuracy: 0.9787\n",
            "Epoch 385/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0398 - accuracy: 0.9895 - val_loss: 0.0924 - val_accuracy: 0.9787\n",
            "Epoch 386/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0397 - accuracy: 0.9895 - val_loss: 0.0924 - val_accuracy: 0.9787\n",
            "Epoch 387/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0396 - accuracy: 0.9895 - val_loss: 0.0925 - val_accuracy: 0.9787\n",
            "Epoch 388/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0396 - accuracy: 0.9895 - val_loss: 0.0925 - val_accuracy: 0.9787\n",
            "Epoch 389/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0395 - accuracy: 0.9895 - val_loss: 0.0926 - val_accuracy: 0.9787\n",
            "Epoch 390/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0394 - accuracy: 0.9895 - val_loss: 0.0927 - val_accuracy: 0.9787\n",
            "Epoch 391/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0394 - accuracy: 0.9895 - val_loss: 0.0927 - val_accuracy: 0.9787\n",
            "Epoch 392/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0393 - accuracy: 0.9895 - val_loss: 0.0928 - val_accuracy: 0.9787\n",
            "Epoch 393/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0393 - accuracy: 0.9869 - val_loss: 0.0928 - val_accuracy: 0.9787\n",
            "Epoch 394/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0392 - accuracy: 0.9895 - val_loss: 0.0929 - val_accuracy: 0.9787\n",
            "Epoch 395/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0392 - accuracy: 0.9869 - val_loss: 0.0930 - val_accuracy: 0.9787\n",
            "Epoch 396/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0391 - accuracy: 0.9895 - val_loss: 0.0932 - val_accuracy: 0.9787\n",
            "Epoch 397/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0391 - accuracy: 0.9895 - val_loss: 0.0932 - val_accuracy: 0.9787\n",
            "Epoch 398/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0390 - accuracy: 0.9895 - val_loss: 0.0932 - val_accuracy: 0.9787\n",
            "Epoch 399/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0390 - accuracy: 0.9895 - val_loss: 0.0933 - val_accuracy: 0.9787\n",
            "Epoch 400/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0389 - accuracy: 0.9895 - val_loss: 0.0934 - val_accuracy: 0.9787\n",
            "Epoch 401/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0389 - accuracy: 0.9895 - val_loss: 0.0934 - val_accuracy: 0.9787\n",
            "Epoch 402/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0388 - accuracy: 0.9895 - val_loss: 0.0935 - val_accuracy: 0.9787\n",
            "Epoch 403/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0388 - accuracy: 0.9895 - val_loss: 0.0935 - val_accuracy: 0.9787\n",
            "Epoch 404/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0387 - accuracy: 0.9895 - val_loss: 0.0936 - val_accuracy: 0.9787\n",
            "Epoch 405/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0387 - accuracy: 0.9895 - val_loss: 0.0936 - val_accuracy: 0.9787\n",
            "Epoch 406/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0386 - accuracy: 0.9895 - val_loss: 0.0937 - val_accuracy: 0.9787\n",
            "Epoch 407/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0385 - accuracy: 0.9895 - val_loss: 0.0938 - val_accuracy: 0.9787\n",
            "Epoch 408/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0385 - accuracy: 0.9895 - val_loss: 0.0938 - val_accuracy: 0.9787\n",
            "Epoch 409/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0385 - accuracy: 0.9895 - val_loss: 0.0940 - val_accuracy: 0.9787\n",
            "Epoch 410/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0384 - accuracy: 0.9895 - val_loss: 0.0940 - val_accuracy: 0.9787\n",
            "Epoch 411/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0384 - accuracy: 0.9895 - val_loss: 0.0941 - val_accuracy: 0.9787\n",
            "Epoch 412/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0383 - accuracy: 0.9895 - val_loss: 0.0942 - val_accuracy: 0.9787\n",
            "Epoch 413/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0383 - accuracy: 0.9895 - val_loss: 0.0943 - val_accuracy: 0.9787\n",
            "Epoch 414/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0382 - accuracy: 0.9895 - val_loss: 0.0943 - val_accuracy: 0.9787\n",
            "Epoch 415/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0381 - accuracy: 0.9895 - val_loss: 0.0944 - val_accuracy: 0.9787\n",
            "Epoch 416/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0381 - accuracy: 0.9895 - val_loss: 0.0944 - val_accuracy: 0.9787\n",
            "Epoch 417/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0381 - accuracy: 0.9869 - val_loss: 0.0945 - val_accuracy: 0.9787\n",
            "Epoch 418/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0380 - accuracy: 0.9895 - val_loss: 0.0946 - val_accuracy: 0.9787\n",
            "Epoch 419/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0380 - accuracy: 0.9869 - val_loss: 0.0947 - val_accuracy: 0.9787\n",
            "Epoch 420/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0379 - accuracy: 0.9869 - val_loss: 0.0947 - val_accuracy: 0.9787\n",
            "Epoch 421/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0378 - accuracy: 0.9869 - val_loss: 0.0948 - val_accuracy: 0.9787\n",
            "Epoch 422/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0378 - accuracy: 0.9869 - val_loss: 0.0948 - val_accuracy: 0.9787\n",
            "Epoch 423/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0378 - accuracy: 0.9869 - val_loss: 0.0948 - val_accuracy: 0.9787\n",
            "Epoch 424/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0377 - accuracy: 0.9869 - val_loss: 0.0949 - val_accuracy: 0.9787\n",
            "Epoch 425/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0377 - accuracy: 0.9869 - val_loss: 0.0950 - val_accuracy: 0.9787\n",
            "Epoch 426/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0377 - accuracy: 0.9869 - val_loss: 0.0951 - val_accuracy: 0.9787\n",
            "Epoch 427/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0376 - accuracy: 0.9895 - val_loss: 0.0951 - val_accuracy: 0.9787\n",
            "Epoch 428/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0375 - accuracy: 0.9895 - val_loss: 0.0953 - val_accuracy: 0.9787\n",
            "Epoch 429/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0375 - accuracy: 0.9869 - val_loss: 0.0953 - val_accuracy: 0.9787\n",
            "Epoch 430/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0375 - accuracy: 0.9869 - val_loss: 0.0953 - val_accuracy: 0.9787\n",
            "Epoch 431/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0374 - accuracy: 0.9869 - val_loss: 0.0954 - val_accuracy: 0.9787\n",
            "Epoch 432/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0373 - accuracy: 0.9869 - val_loss: 0.0955 - val_accuracy: 0.9787\n",
            "Epoch 433/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0373 - accuracy: 0.9869 - val_loss: 0.0955 - val_accuracy: 0.9787\n",
            "Epoch 434/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0373 - accuracy: 0.9869 - val_loss: 0.0956 - val_accuracy: 0.9787\n",
            "Epoch 435/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0372 - accuracy: 0.9869 - val_loss: 0.0956 - val_accuracy: 0.9787\n",
            "Epoch 436/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0372 - accuracy: 0.9869 - val_loss: 0.0957 - val_accuracy: 0.9787\n",
            "Epoch 437/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0371 - accuracy: 0.9869 - val_loss: 0.0957 - val_accuracy: 0.9787\n",
            "Epoch 438/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0371 - accuracy: 0.9869 - val_loss: 0.0959 - val_accuracy: 0.9787\n",
            "Epoch 439/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0371 - accuracy: 0.9869 - val_loss: 0.0959 - val_accuracy: 0.9787\n",
            "Epoch 440/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0370 - accuracy: 0.9869 - val_loss: 0.0960 - val_accuracy: 0.9787\n",
            "Epoch 441/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0369 - accuracy: 0.9869 - val_loss: 0.0960 - val_accuracy: 0.9787\n",
            "Epoch 442/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0369 - accuracy: 0.9869 - val_loss: 0.0961 - val_accuracy: 0.9787\n",
            "Epoch 443/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0368 - accuracy: 0.9895 - val_loss: 0.0961 - val_accuracy: 0.9787\n",
            "Epoch 444/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0369 - accuracy: 0.9869 - val_loss: 0.0962 - val_accuracy: 0.9787\n",
            "Epoch 445/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0368 - accuracy: 0.9869 - val_loss: 0.0963 - val_accuracy: 0.9787\n",
            "Epoch 446/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0367 - accuracy: 0.9869 - val_loss: 0.0963 - val_accuracy: 0.9787\n",
            "Epoch 447/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0367 - accuracy: 0.9869 - val_loss: 0.0964 - val_accuracy: 0.9787\n",
            "Epoch 448/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0367 - accuracy: 0.9869 - val_loss: 0.0964 - val_accuracy: 0.9787\n",
            "Epoch 449/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0366 - accuracy: 0.9869 - val_loss: 0.0965 - val_accuracy: 0.9787\n",
            "Epoch 450/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0365 - accuracy: 0.9869 - val_loss: 0.0967 - val_accuracy: 0.9787\n",
            "Epoch 451/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0365 - accuracy: 0.9895 - val_loss: 0.0968 - val_accuracy: 0.9787\n",
            "Epoch 452/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0365 - accuracy: 0.9869 - val_loss: 0.0968 - val_accuracy: 0.9787\n",
            "Epoch 453/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0364 - accuracy: 0.9869 - val_loss: 0.0969 - val_accuracy: 0.9787\n",
            "Epoch 454/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0364 - accuracy: 0.9869 - val_loss: 0.0969 - val_accuracy: 0.9787\n",
            "Epoch 455/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0363 - accuracy: 0.9869 - val_loss: 0.0969 - val_accuracy: 0.9787\n",
            "Epoch 456/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0363 - accuracy: 0.9869 - val_loss: 0.0971 - val_accuracy: 0.9787\n",
            "Epoch 457/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0362 - accuracy: 0.9869 - val_loss: 0.0972 - val_accuracy: 0.9787\n",
            "Epoch 458/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0362 - accuracy: 0.9869 - val_loss: 0.0972 - val_accuracy: 0.9787\n",
            "Epoch 459/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0362 - accuracy: 0.9869 - val_loss: 0.0972 - val_accuracy: 0.9787\n",
            "Epoch 460/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0361 - accuracy: 0.9869 - val_loss: 0.0973 - val_accuracy: 0.9787\n",
            "Epoch 461/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0361 - accuracy: 0.9869 - val_loss: 0.0974 - val_accuracy: 0.9787\n",
            "Epoch 462/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0360 - accuracy: 0.9869 - val_loss: 0.0975 - val_accuracy: 0.9787\n",
            "Epoch 463/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0360 - accuracy: 0.9869 - val_loss: 0.0975 - val_accuracy: 0.9787\n",
            "Epoch 464/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0359 - accuracy: 0.9869 - val_loss: 0.0976 - val_accuracy: 0.9787\n",
            "Epoch 465/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0359 - accuracy: 0.9869 - val_loss: 0.0977 - val_accuracy: 0.9787\n",
            "Epoch 466/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0359 - accuracy: 0.9869 - val_loss: 0.0978 - val_accuracy: 0.9787\n",
            "Epoch 467/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0358 - accuracy: 0.9869 - val_loss: 0.0978 - val_accuracy: 0.9787\n",
            "Epoch 468/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0358 - accuracy: 0.9869 - val_loss: 0.0979 - val_accuracy: 0.9787\n",
            "Epoch 469/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0358 - accuracy: 0.9869 - val_loss: 0.0980 - val_accuracy: 0.9787\n",
            "Epoch 470/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0357 - accuracy: 0.9869 - val_loss: 0.0981 - val_accuracy: 0.9787\n",
            "Epoch 471/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0357 - accuracy: 0.9869 - val_loss: 0.0981 - val_accuracy: 0.9787\n",
            "Epoch 472/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0356 - accuracy: 0.9869 - val_loss: 0.0981 - val_accuracy: 0.9787\n",
            "Epoch 473/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0356 - accuracy: 0.9869 - val_loss: 0.0981 - val_accuracy: 0.9787\n",
            "Epoch 474/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0356 - accuracy: 0.9869 - val_loss: 0.0982 - val_accuracy: 0.9787\n",
            "Epoch 475/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0355 - accuracy: 0.9869 - val_loss: 0.0982 - val_accuracy: 0.9787\n",
            "Epoch 476/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0355 - accuracy: 0.9869 - val_loss: 0.0983 - val_accuracy: 0.9787\n",
            "Epoch 477/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0354 - accuracy: 0.9869 - val_loss: 0.0985 - val_accuracy: 0.9787\n",
            "Epoch 478/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0354 - accuracy: 0.9869 - val_loss: 0.0985 - val_accuracy: 0.9787\n",
            "Epoch 479/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0353 - accuracy: 0.9869 - val_loss: 0.0986 - val_accuracy: 0.9787\n",
            "Epoch 480/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0353 - accuracy: 0.9869 - val_loss: 0.0987 - val_accuracy: 0.9787\n",
            "Epoch 481/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0353 - accuracy: 0.9869 - val_loss: 0.0987 - val_accuracy: 0.9787\n",
            "Epoch 482/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0352 - accuracy: 0.9869 - val_loss: 0.0987 - val_accuracy: 0.9787\n",
            "Epoch 483/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0352 - accuracy: 0.9869 - val_loss: 0.0989 - val_accuracy: 0.9787\n",
            "Epoch 484/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0352 - accuracy: 0.9869 - val_loss: 0.0990 - val_accuracy: 0.9787\n",
            "Epoch 485/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0351 - accuracy: 0.9869 - val_loss: 0.0990 - val_accuracy: 0.9787\n",
            "Epoch 486/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0351 - accuracy: 0.9869 - val_loss: 0.0990 - val_accuracy: 0.9787\n",
            "Epoch 487/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0350 - accuracy: 0.9869 - val_loss: 0.0990 - val_accuracy: 0.9787\n",
            "Epoch 488/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0350 - accuracy: 0.9869 - val_loss: 0.0991 - val_accuracy: 0.9787\n",
            "Epoch 489/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0350 - accuracy: 0.9869 - val_loss: 0.0992 - val_accuracy: 0.9787\n",
            "Epoch 490/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0349 - accuracy: 0.9869 - val_loss: 0.0993 - val_accuracy: 0.9787\n",
            "Epoch 491/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0349 - accuracy: 0.9869 - val_loss: 0.0994 - val_accuracy: 0.9787\n",
            "Epoch 492/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0349 - accuracy: 0.9869 - val_loss: 0.0994 - val_accuracy: 0.9787\n",
            "Epoch 493/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0348 - accuracy: 0.9869 - val_loss: 0.0994 - val_accuracy: 0.9787\n",
            "Epoch 494/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0348 - accuracy: 0.9895 - val_loss: 0.0996 - val_accuracy: 0.9787\n",
            "Epoch 495/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0348 - accuracy: 0.9895 - val_loss: 0.0996 - val_accuracy: 0.9787\n",
            "Epoch 496/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0347 - accuracy: 0.9895 - val_loss: 0.0997 - val_accuracy: 0.9787\n",
            "Epoch 497/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0347 - accuracy: 0.9895 - val_loss: 0.0998 - val_accuracy: 0.9787\n",
            "Epoch 498/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0346 - accuracy: 0.9895 - val_loss: 0.0999 - val_accuracy: 0.9787\n",
            "Epoch 499/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0346 - accuracy: 0.9895 - val_loss: 0.0999 - val_accuracy: 0.9787\n",
            "Epoch 500/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0346 - accuracy: 0.9895 - val_loss: 0.1000 - val_accuracy: 0.9787\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0345 - accuracy: 0.9895\n",
            "Train score: [0.034497786313295364, 0.9895012974739075]\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.1000 - accuracy: 0.9787\n",
            "Test score: [0.09996064007282257, 0.978723406791687]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(r.history['loss'], label='loss') #training loss\n",
        "plt.plot(r.history['val_loss'], label='val_loss') #validation loss\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "a1Nl2A4NBYbe",
        "outputId": "419f6305-e223-4951-de20-e5ee98c3fa60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f02f861a3d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(r.history['accuracy'], label='acc') #training loss\n",
        "plt.plot(r.history['val_accuracy'], label='val_acc') #validation loss\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "qrgPd07C9za1",
        "outputId": "cb13d28e-fa19-444c-88bd-eb7c20f3ed9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f02f85cedc0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 2: Making Predictions\n",
        "\n",
        "P = model.predict(test[x])\n",
        "print(P) # they are outputs of the sigmoid, interpreted as probabilities p(y = 1 | x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoyH7MDo7SF9",
        "outputId": "a83148d3-0d85-41f1-9125-f797ed99c201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 3ms/step\n",
            "[[9.99998093e-01]\n",
            " [9.99957502e-01]\n",
            " [8.14450502e-01]\n",
            " [9.98996675e-01]\n",
            " [5.25701435e-05]\n",
            " [6.95884106e-13]\n",
            " [9.99971747e-01]\n",
            " [9.99999881e-01]\n",
            " [4.77021700e-03]\n",
            " [9.99993145e-01]\n",
            " [9.89623547e-01]\n",
            " [2.41026137e-04]\n",
            " [1.91157824e-07]\n",
            " [1.00000000e+00]\n",
            " [9.99995708e-01]\n",
            " [9.99787688e-01]\n",
            " [9.04050231e-01]\n",
            " [9.99904454e-01]\n",
            " [6.40680417e-02]\n",
            " [9.93324935e-01]\n",
            " [9.99973118e-01]\n",
            " [9.54219401e-01]\n",
            " [9.99973834e-01]\n",
            " [9.99980807e-01]\n",
            " [9.99701321e-01]\n",
            " [9.98029947e-01]\n",
            " [4.19625867e-04]\n",
            " [7.23790348e-01]\n",
            " [9.99948144e-01]\n",
            " [9.99757588e-01]\n",
            " [9.99961615e-01]\n",
            " [9.99146700e-01]\n",
            " [3.16714728e-03]\n",
            " [9.99927104e-01]\n",
            " [3.73032417e-05]\n",
            " [9.99952495e-01]\n",
            " [9.99926031e-01]\n",
            " [9.99984622e-01]\n",
            " [9.99993682e-01]\n",
            " [8.93471846e-16]\n",
            " [9.99183238e-01]\n",
            " [9.99997795e-01]\n",
            " [9.99857783e-01]\n",
            " [9.97683823e-01]\n",
            " [9.99993920e-01]\n",
            " [9.97595370e-01]\n",
            " [1.79590641e-12]\n",
            " [9.99992430e-01]\n",
            " [9.97429848e-01]\n",
            " [2.62489630e-09]\n",
            " [2.61792284e-03]\n",
            " [2.11255960e-04]\n",
            " [7.28691788e-03]\n",
            " [9.99998331e-01]\n",
            " [9.98738348e-01]\n",
            " [3.86625459e-07]\n",
            " [1.07776135e-08]\n",
            " [9.99967515e-01]\n",
            " [2.91822108e-19]\n",
            " [9.99921501e-01]\n",
            " [6.59447864e-18]\n",
            " [9.95306015e-01]\n",
            " [9.99936640e-01]\n",
            " [3.90928835e-06]\n",
            " [1.02497506e-05]\n",
            " [9.99999940e-01]\n",
            " [6.01493699e-09]\n",
            " [1.34652691e-06]\n",
            " [9.62243438e-01]\n",
            " [9.99999642e-01]\n",
            " [9.94387865e-01]\n",
            " [9.98675466e-01]\n",
            " [4.93529591e-15]\n",
            " [9.99999940e-01]\n",
            " [9.99970078e-01]\n",
            " [9.95335877e-01]\n",
            " [6.40555648e-31]\n",
            " [1.00000000e+00]\n",
            " [9.99787092e-01]\n",
            " [2.64845590e-10]\n",
            " [5.34345920e-04]\n",
            " [9.99870539e-01]\n",
            " [9.99987066e-01]\n",
            " [3.05415015e-04]\n",
            " [1.54029345e-04]\n",
            " [2.13344308e-07]\n",
            " [1.91915081e-10]\n",
            " [1.00000000e+00]\n",
            " [9.99852955e-01]\n",
            " [1.16728160e-09]\n",
            " [9.64757025e-01]\n",
            " [9.99955535e-01]\n",
            " [9.99715805e-01]\n",
            " [4.03054446e-06]\n",
            " [2.67147133e-12]\n",
            " [9.99999046e-01]\n",
            " [1.54861389e-02]\n",
            " [1.06803327e-07]\n",
            " [9.99997973e-01]\n",
            " [7.37610521e-14]\n",
            " [9.99951065e-01]\n",
            " [5.24434654e-05]\n",
            " [2.67048359e-19]\n",
            " [9.99900222e-01]\n",
            " [4.27319231e-13]\n",
            " [9.65919316e-01]\n",
            " [9.96806502e-01]\n",
            " [9.98829782e-01]\n",
            " [1.22830737e-04]\n",
            " [2.42984022e-14]\n",
            " [9.98065114e-01]\n",
            " [6.56313685e-17]\n",
            " [9.99999583e-01]\n",
            " [9.88364160e-01]\n",
            " [7.92514765e-09]\n",
            " [9.99997437e-01]\n",
            " [9.99999225e-01]\n",
            " [9.94678259e-01]\n",
            " [7.32255936e-01]\n",
            " [9.99998510e-01]\n",
            " [9.99998212e-01]\n",
            " [9.99999344e-01]\n",
            " [1.58274850e-06]\n",
            " [9.99924779e-01]\n",
            " [5.78421772e-01]\n",
            " [9.99645054e-01]\n",
            " [9.99976575e-01]\n",
            " [9.99771178e-01]\n",
            " [9.99944985e-01]\n",
            " [9.99875605e-01]\n",
            " [3.03076338e-02]\n",
            " [3.97683469e-10]\n",
            " [9.99985397e-01]\n",
            " [1.66665737e-12]\n",
            " [9.97811913e-01]\n",
            " [6.44943357e-01]\n",
            " [2.12934864e-10]\n",
            " [3.09006083e-08]\n",
            " [4.87776424e-06]\n",
            " [9.99999821e-01]\n",
            " [2.27586083e-09]\n",
            " [9.99999642e-01]\n",
            " [9.99938011e-01]\n",
            " [9.99996781e-01]\n",
            " [2.31083669e-03]\n",
            " [2.36153835e-03]\n",
            " [9.56673759e-13]\n",
            " [3.75216091e-12]\n",
            " [1.97448389e-06]\n",
            " [9.99982297e-01]\n",
            " [9.90266562e-01]\n",
            " [7.67701014e-09]\n",
            " [4.52055948e-09]\n",
            " [9.98924494e-01]\n",
            " [4.60772299e-06]\n",
            " [9.93718207e-01]\n",
            " [9.99989688e-01]\n",
            " [9.99990582e-01]\n",
            " [8.90193999e-01]\n",
            " [2.13590978e-10]\n",
            " [1.45321228e-02]\n",
            " [1.49603371e-10]\n",
            " [1.50282995e-03]\n",
            " [9.99998391e-01]\n",
            " [5.15935317e-05]\n",
            " [9.51498449e-01]\n",
            " [9.97751236e-01]\n",
            " [9.99996066e-01]\n",
            " [2.97634035e-11]\n",
            " [9.99964476e-01]\n",
            " [3.26583577e-05]\n",
            " [9.99969065e-01]\n",
            " [9.98230219e-01]\n",
            " [9.99255180e-01]\n",
            " [9.99999762e-01]\n",
            " [7.23521168e-07]\n",
            " [5.28206954e-07]\n",
            " [9.99880672e-01]\n",
            " [1.75233017e-05]\n",
            " [9.52613711e-01]\n",
            " [9.94758487e-01]\n",
            " [9.75170955e-02]\n",
            " [9.96894181e-01]\n",
            " [8.38219106e-01]\n",
            " [9.94161069e-01]\n",
            " [9.95772660e-01]\n",
            " [9.60371614e-01]\n",
            " [8.70459080e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Round to get the actual predictions\n",
        "# Note: has to be flattened since the targets are size (N,) while the predictions are size (N,1)\n",
        "\n",
        "#in pratica ti ritorna una colonna di N elementi noi vogliamo un vettor riga di N elem\n",
        "import numpy as np\n",
        "P = np.round(P).flatten()\n",
        "print(P)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5sUL9u77aQq",
        "outputId": "63f391fa-0866-4d2c-9782-8cfd5753e7f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
            " 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1.\n",
            " 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1.\n",
            " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1.\n",
            " 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1.\n",
            " 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the accuracy, compare it to evaluate() output\n",
        "\n",
        "# SOLO CON INTERI: con == si fa una element wise comparazione nel numpy array e se la comparazione √® vera il valore √® sostituito con 1, se no con 0\n",
        "print(\"Manually calculated accuracy:\", np.mean(P == test[y]))\n",
        "#Alla fine √® la stessa cosa\n",
        "print(\"Evaluate output:\", model.evaluate(test[x], test[y]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rP9w-8Bu7bkG",
        "outputId": "bb0333b9-092e-4048-84c1-5f2e7863876d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manually calculated accuracy: 0.9787234042553191\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1000 - accuracy: 0.9787\n",
            "Evaluate output: [0.09996064007282257, 0.978723406791687]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Part 3: Saving and Loading a Model\n",
        "\n",
        "# Let's now save our model to a file\n",
        "model.save('linearclassifier.h5')\n",
        "\n",
        "# Check that the model file exists\n",
        "!ls -lh \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Let's load the model and confirm that it still works\n",
        "# Note: there is a bug in Keras where load/save only works if you DON'T use the Input() layer explicitly\n",
        "# So, make sure you define the model with ONLY Dense(1, input_shape=(D,))\n",
        "# At least, until the bug is fixed\n",
        "# https://github.com/keras-team/keras/issues/10417\n",
        "model = tf.keras.models.load_model('linearclassifier.h5')\n",
        "print(model.layers)\n",
        "model.evaluate(test[x], test[y])\n",
        "\n",
        "\n",
        "# Download the file - requires Chrome (at this point)\n",
        "from google.colab import files\n",
        "files.download('linearclassifier.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "tuchctDl7dTU",
        "outputId": "d03aa973-799d-41b6-db93-0bdca9e22a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 24K\n",
            "-rw-r--r-- 1 root root  19K Jan 26 16:56 linearclassifier.h5\n",
            "drwxr-xr-x 1 root root 4.0K Jan 24 14:38 sample_data\n",
            "[<keras.layers.core.dense.Dense object at 0x7f02f2e2a6a0>]\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.1000 - accuracy: 0.9787\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3eaa5226-4e61-44b8-aa78-da58a6cd134d\", \"linearclassifier.h5\", 19312)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}