{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gStc4mUuyx5M"
      },
      "outputs": [],
      "source": [
        "# Install TensorFlow\n",
        "# !pip install -q tensorflow-gpu==2.0.0-beta1\n",
        "\n",
        "try:\n",
        "  %tensorflow_version 2.x  # Colab only.\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Just a simple test\n",
        "sentences = [\n",
        "    \"I like eggs and ham.\",\n",
        "    \"I love chocolate and bunnies.\",\n",
        "    \"I hate onions.\"\n",
        "]\n",
        "\n",
        "MAX_VOCAB_SIZE = 20000  #20K è il numero di parole normalmente utilizzate nella vita quotidiana.\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE) # è come fare il .fit()\n",
        "tokenizer.fit_on_texts(sentences)               \n",
        "sequences = tokenizer.texts_to_sequences(sentences) # è come fare la .transform()\n",
        "\n",
        "print(sequences) #sequenza delle liste, sono solo 3 perchè abbiamo 3 frasi \n",
        "\n"
      ],
      "metadata": {
        "id": "5fT_0mE0y18-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How to get the word to index mapping? (Per scoprire quale parola corrisponde al numero basta chiamare questa funzione che ritorna le chaivi)\n",
        "tokenizer.word_index\n"
      ],
      "metadata": {
        "id": "8bgIblxGy5Ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ora facciamo un po' di prove sui padding :"
      ],
      "metadata": {
        "id": "gNduI00Y0LRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use the defaults (Max lenght = frase + lunga, di default il padding è messo all'inizio)\n",
        "\n",
        "data = pad_sequences(sequences)\n",
        "print(data)"
      ],
      "metadata": {
        "id": "es9yhDMSy7k5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_SEQUENCE_LENGTH = 5 #Idem a prima perchè la lunghezza maggiore era 5\n",
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print(data)\n"
      ],
      "metadata": {
        "id": "WkNt3S-Ey9b1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
        "print(data)"
      ],
      "metadata": {
        "id": "LNFi4HPfy_bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# too much padding -> le frasi venfono portate a 6 di max dimension, non si perde informazione comuqnue\n",
        "data = pad_sequences(sequences, maxlen=6)\n",
        "print(data)"
      ],
      "metadata": {
        "id": "fNoX0owgzBXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# truncation\n",
        "data = pad_sequences(sequences, maxlen=4)\n",
        "print(data)\n"
      ],
      "metadata": {
        "id": "fxrQJeIFzDj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#truncating post\n",
        "\n",
        "data = pad_sequences(sequences, maxlen=4, truncating='post')\n",
        "print(data)"
      ],
      "metadata": {
        "id": "T1BGmXCmzGAr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}